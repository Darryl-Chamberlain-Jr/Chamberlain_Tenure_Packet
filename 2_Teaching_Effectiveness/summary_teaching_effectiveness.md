# Teaching Philosophy - Everyone Can Excel at Mathematics
One of the fundamental assumptions that drive my teaching is that every student, regardless of background, age, or a million other factors, can excel at mathematics. Many of the students that come into our classroom believe "they are not math people" as if people are born to do mathematics. Due to the hirearchial nature of mathematics, topics build on other topics. Students, through no fault of their own, may not have the necessary foundation to immediately jump into the topic of the course. Students preceive this as "failing" or "not being good at math", but it just means they aren't ready *yet*. My strategies to teaching rely on bridging the gap between where students are and where we want them to be in the course. 

Regardless of the modality I employ, students need a great deal of feedback. I commonly achieve this feedback through technology. When building skills like solving equations or practicing mathematics, I rely on online homework systems. This does not just mean paid third party software as I have previously written my own open-source homework system for College Algebra. For students who are struggling with their homework, I will use portions of this open-source homework system to fill gaps in their knowledge. For example, students commonly have difficulty with factoring trinomials. My open-source homework page for factoring can be found at: https://xronos.clas.ufl.edu/ufmac1105/coreModules/module4Activity/factoringTrinomials. Students that are struggling are sent to this page for additional help that breaks down the topic in easy-to-understand stages. A long-term goal is to create such an open-source homework system specific to math courses here at ERAU-W. Moreover, I am constantly learning about new academic technology to enhance student learning. I developed an interactive to help students visualize and check their answers for a particularly challenging discussion problem. I am currently extending that interactive to be a full discovery-based learning activity that responds as students posit how to progress in a question with multiple ways to find the answer. The key to these types of activties are that they get students to engage with the material until they respond in expected ways. With traditional textbook homework that students *may* find answers to some of their work in the back of a book, these activities allow students to re-adjust their thinking before it turns to long-term memory. My wealth of additionial learning resources lets me help students who may have a larger gap than others catch up to the expectations of the course and succeed.

For activities where automated feedback isn't appropriate, I encourage peer feedback around *how* students think and not on getting "correct" answers. Students reviewing other students' work is an effective way for students to reflect on topics they have already seen and reinforce concepts. In these activities, students are graded on their effort to provide feedback rather than provide correct answers. For example, when I developed discussion activities for Math 111, student replies to others had purpose. Rather than just checking if a student solved an equation "correctly", students critically reviewed others' Study Guides, Concept Videos, and how students solved a question. Students have responded positively to the focus on process over product, as illustrated in my reflection on student course evaluations. Peer feedback in group work was most effective in the EagleVision October 2022 course I taught. Body language and tone of voice are far easier to convey in person, which led students to feel comfortable sharing their sometimes erroneous thoughts with their group or the class in general.

I have run two teaching experiements with Math 111 - one of the courses I am the Course Developer and Course Mentor. The first examined student Show Work, scores on midterm/final, and their understandng of fundamental concepts in the course. The Show Work illuminated new ways students thought as they approached problems specific to the ERAU-W course that I've incorporated in automated feedback I've written. The comparison of scores on midterm/final and understanding of fundamental concepts showed me students can generally do well on the high-stakes assignments that are currently in the course, but that this does not translate into learning concepts. To that end, I'm designing an activity much like a "Choose-Your-Own-Adventure" story. This activity will rely on automated feedback (based in the Show Work analysis of how ERAU-W students think) to walk students through the process of solving a typical precalculus question. Unlike assignments students might see in paid third-party sites, the focus is on how students think as they solve the problem. The activity will prompt the student to (1) consider any additional information they want to solve for, (2) approached they want to take, and (3) encourage students to extend their process to a similar question. There will be hidden trackers that save student responses throughout the process to check if students are making mathematically sound steps as they go and providing feedback if they do not. This focus on the process both aligns with my overall teaching enviornment of process over product as well as engenders high-level mathematical thinking. A follow-up study will test whether merely completing this activity is predictive of student understanding and could form the foundation of a non-traditional summative assessment to replace high-stakes exams.

Student evaluations are known to be faulty methods for evaluating instructor effectiveness in courses due to conscious and unconscious student biases as well as students not being subject matter nor pedagogical experts. Student evaluations do provide accurate representations of *satisfaction* with a course. Interpreted student comments can also shed light on potential issues in a course. For example, when a student says "Instructions for this activity were unclear" when the instructions are 6 pages long, it may mean that there was no short summary for the instructors or that the instructors were not formatted for skimming. Therefore, as long as my quantitative evaluations are above 4.5 for each question (which they have been for every course I've taught), I focus only on student comments. Students have responded overwhelmingly positively to my methods of teaching courses at ERAU-W. As noted in my reflection on Student Course Evaluations, 45/46 were entirely positive and noted the extensive feedback I provide students, the numerous helpful resources I have when needed, and the accepting environment I engender with my process over product mentality. 

To evaluate the subject matter knowledge and pedagogical choices of the courses I design, I rely on expert faculty. When Dr. Zackery Reed reviewed my MATH 111 EagleVision course, he said

>Dr. Chamberlain demonstrates a productive balance of direct instruction (i.e., lecture) and active learning activities. This suggests an intentional awareness of student attention span needs, and more importantly an implementation of currently known best practices for mathematics pedagogy. 

This is evidence for productive teaching practices that students would not be able to evaluate. I also rely on adjunct feedback when it comes to individual instructional activities. For example, when redeveloping MATH 111 Pre-Calculus for Aviation, I significantly reworked many of the discussions to encourage higher-level mathematical thinking. One discussion in particular has received both hate and love by adjuncts. The question requires students to reason how to compensate for wind when flying between two cities. The question is written so that there are numerous ways students can reason through and "solve" for the specific correction in the problem. This led to a spike in students asking instructors questions and time to grade student responses as the process of reasoning through the task was not unique. This led to instructor comments such as:

> I have a feeling that this problem could be too complicated in an introductory level course. Admittedly, even I had a hard time figuring out how to tackle this problem until I looked at the solution guide.  I have never seen such an applied vector problem before this one.

> Attached are three students approach to the problem. The Answer Key provided shows a different approach to working the problem.  Could you look over these students approach and provide me with any suggestions on how to best help them? 

>Several of my students have asked for the velocity or speed of the airplane. I told them they have all the information that is needed to solve the problem and suggested that they make a sketch. I am afraid this isn't going to go too well! 

>The new Module 7 Group Discussion Exercise in Math 111 was a tremendous addition to the course. Cognitive presence was demonstrated significantly in the various ways students sketched, formulated, solved and analyzed the given problem. Several students supplemented the work of others through extensive collaboration and tackling the problem from different angles...literally and figuratively! This was a welcome addition to an "aviation" course which up until recently didn't have many aviation applications or examples. I received the most comments and questions from students (by far) about the discussion exercise. 

All of these comments point to an increased cognitive demand for the discussion post. While difficulty can be argued, many students were and are able to reason through the discussion post by the end of the week. This suggests the question is not too complicated, but IS a spike in difficulty from what they might see on the homework and exams. The second comment in particular highlights how there is no one way to reason through the task, which was precisely the point. The third comment points to the need for instructors to engage with the task beyond "correct" or "incorrect" and provides a genuine opportunity for teacher-to-student learning. The fourth comment shows how the discussion works when the instructor has the subject matter expertise to engage with students. While I believe this discussion needs more materials for instructor support (numerous examples of productive thinking, a more clear rubric that tells instructors to grade on the process over the final answer) and student support (interactive elements that let students experimentally test their answers), the discussion is a positive step toward active math engagement in an online course. Moreover, it fits perfectly with my overall philosophy that all students CAN do mathematics and thus they can be challenged with an interesting question in a low-stakes environment.

